{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "468c9f9b-258d-4e24-8d07-f10053cb43ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Objective\n",
    "\n",
    "With the purpose of testing dqx capabilities in data quality checks we are going to modify the Netflix dataset to include new \"trash\" data to test dqx boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c007cca-9974-4085-bc59-b677b811ddb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read original data\n",
    "\n",
    "raw_data = spark.read.options(header=True, inferSchema=True).csv(\"/Volumes/workspace/default/files/DQX_demo_data/netflix1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "634fd7ac-f87f-45d9-8be5-41febd61a4ab",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756767243902}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, rand, when, lit, concat, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import random\n",
    "\n",
    "# Load dataset\n",
    "df = spark.read.csv(\"/Volumes/workspace/default/files/DQX_demo_data/netflix1.csv\", header=True, inferSchema=False)\n",
    "\n",
    "# --- 1. show_id: malformed IDs ---\n",
    "df = df.withColumn(\n",
    "    \"show_id\",\n",
    "    when(rand() < 0.05, concat(lit(\"xx\"), col(\"show_id\"))).\n",
    "    when(rand() < 0.03, lit(None)).otherwise(col(\"show_id\"))\n",
    ")\n",
    "\n",
    "# --- 2. type: wrong / lowercase values ---\n",
    "df = df.withColumn(\n",
    "    \"type\",\n",
    "    when(rand() < 0.05, lit(\"movie\"))\n",
    "    .when(rand() < 0.02, lit(\"Documentary\"))\n",
    "    .otherwise(col(\"type\"))\n",
    ")\n",
    "\n",
    "# --- 3. title: nulls or typos ---\n",
    "df = df.withColumn(\n",
    "    \"title\",\n",
    "    when(rand() < 0.05, lit(None))\n",
    "    .when(rand() < 0.05, concat(col(\"title\"), lit(\"@@@\")))\n",
    "    .otherwise(col(\"title\"))\n",
    ")\n",
    "\n",
    "# --- 4. director: missing or numbers ---\n",
    "df = df.withColumn(\n",
    "    \"director\",\n",
    "    when(rand() < 0.05, lit(None))\n",
    "    .when(rand() < 0.03, concat(col(\"director\"), lit(\"123\")))\n",
    "    .otherwise(col(\"director\"))\n",
    ")\n",
    "\n",
    "# --- 5. country: inconsistent spellings ---\n",
    "df = df.withColumn(\n",
    "    \"country\",\n",
    "    when(rand() < 0.05, lit(\"U.S.\"))\n",
    "    .when(rand() < 0.03, lit(None))\n",
    "    .otherwise(col(\"country\"))\n",
    ")\n",
    "\n",
    "# --- 6. date_added: invalid formats ---\n",
    "df = df.withColumn(\n",
    "    \"date_added\",\n",
    "    when(rand() < 0.05, lit(\"2021-13-40\"))\n",
    "    .when(rand() < 0.03, lit(None))\n",
    "    .otherwise(col(\"date_added\"))\n",
    ")\n",
    "\n",
    "# --- 7. rating: invalid categories ---\n",
    "df = df.withColumn(\n",
    "    \"rating\",\n",
    "    when(rand() < 0.05, lit(\"PG-99\"))\n",
    "    .when(rand() < 0.03, lit(\"tv-ma\"))\n",
    "    .otherwise(col(\"rating\"))\n",
    ")\n",
    "\n",
    "# --- 8. duration: wrong formats ---\n",
    "df = df.withColumn(\n",
    "    \"duration\",\n",
    "    when(rand() < 0.05, lit(\"-100 min\"))\n",
    "    .when(rand() < 0.03, lit(\"90 minutes\"))\n",
    "    .otherwise(col(\"duration\"))\n",
    ")\n",
    "\n",
    "# --- 9. listed_in: dirty categories ---\n",
    "df = df.withColumn(\n",
    "    \"listed_in\",\n",
    "    when(rand() < 0.05, lit(\"Dramas$$$\"))\n",
    "    .when(rand() < 0.03, lit(None))\n",
    "    .otherwise(col(\"listed_in\"))\n",
    ")\n",
    "\n",
    "# --- Add duplicates ---\n",
    "duplicates = df.sample(withReplacement=True, fraction=0.05)\n",
    "df_dirty = df.union(duplicates)\n",
    "display(df_dirty)\n",
    "\n",
    "df_dirty.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"/Volumes/workspace/default/files/DQX_demo_data/netflix_low_quality\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Generate noisy data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
